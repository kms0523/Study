## sum
유한차원 벡터공간 $V / \mathbb F$와 $U,W \le V$가 있을 때, $U$와 $W$의 `합(sum)` $U+W$는 다음과 같이 정의된다.
$$ U+W := \{ u + w \enspace | \enspace u \in U, w \in W \} $$

### 명제1
유한차원 벡터공간 $V / \mathbb F$와 $U,W \le V$가 있을 때, $U+W \le V$임을 증명하여라.

**Proof**

[기본 연산 법칙]  
벡터 공간의 부분집합과 연산을 그대로 사용하기 때문에 교환법칙 분배법칙등이 $F-$가군의 성질들이 전부 성립한다. 

[연산에 닫힘]  
$T_1, T_2 \in L(V,W)$, $a \in \Bbb F$라 하자.

$v_1,v_2 \in V$, $b \in \mathbb{F}$가 있을 때 다음이 성립한다.
$$ \begin{aligned} (aT_1 + T_2)(bv_1 + v_2) &= aT_1(bv_1 + v_2) + T_2(bv_1 + v_2) \\ &= abT_1(v_1) + bT_2(v_1) + aT_1(v_2) + T_2(v_2) \\ &= b(aT_1+T_2)(v_1) + (aT_1+T_2)(v_2) \end{aligned}  $$

따라서, $(aT_1 + T_2)$도 $V$에서 $V$로 가는 선형변환임으로 연산에 닫혀있다. $\quad {_\blacksquare}$

[$+$연산 항등원의 존재성]  
영함수가 다음과 같이 정의되어 있다고 하자.
$$ T_0 : V \rightarrow W \quad s.t. \quad v \mapsto 0_W $$



### 명제2
유한차원 벡터공간 $V / \mathbb F$와 $U,W \le V$가 있을 때, $U \le U+W$와 $W \le U+W$임을 증명하여라.

## direct sum
유한차원 벡터공간 $V / \mathbb F$와 $U,W \le V$가 있을 때, $U \cap W = \{ 0_V \}$면 $U$와 $W$의 `direct sum` $U \oplus W$는 다음과 같이 정의된다.
$$ U \oplus W := \{ u + w \enspace | \enspace u \in U, w \in W \} $$

direct sum은 여러항으로 다음과 같이 확장이 가능하다.

$U_i \le V \enspace i = 1, \cdots, k$가 있을 때, $i = 1, \cdots, k$에 대해 $U_i \cap \bigcup_{\begin{subarray}{l} j = 1 \\ j \neq i \end{subarray}}^k U_j = \{ 0_V \}$면 여러항의 direct sum은 다음과 같이 정의 된다.

$$ \bigoplus_{i=1}^k U_i = \{ u_1 + \cdots + u_k  \enspace | \enspace u_i \in U_i \enspace i = 1, \cdots, k \} $$

### 명제1
유한차원 벡터공간 $V / \mathbb F$와 $W_1, \cdots, W_n \le V$가 있을 때, 다음을 증명하여라.
$$V = W_1 \oplus \cdots \oplus W_n \Rightarrow v \in V, \quad \exist! w_i \in W_i \quad s.t. \quad  v = w_1 + \cdots + w_n$$

**Proof**

$V = W_1 \oplus \cdots \oplus W_n$임으로 $\exist w_i \in W_i \quad s.t \quad v = w_1 + \cdots + w_n$는 자명하다. 

$\exist q_i \in W_i \quad s.t \quad v = q_1 + \cdots + q_n$라 하자. 두 표현식을 빼면 다음과 같다.
$$ 0_V = (w_1 - q_1) + \cdots + (w_n - q_n) $$

$W_i < V$임으로 $w \in W_i$면 $w^{-1} \in W_i$이다. 또한 $W_i \cap W_j = \{ 0_V \}$임으로 $w^{-1} \notin W_j$이다. 즉, $(w_2 - q_2) + \cdots + (w_n - q_n)$은 $(w_1 - q_1)$의 역원이 될 수 없고 식을 만족하기 위해서는 $(w_1 - q_1) = 0_V$이어야 한다. 마찬가지로 $w_i - q_i = 0_V$임으로 $w_i = q_i$이다. 즉, $v = w_1 + \cdots + w_n$를 만족하는 $w_i \in W_i$는 유일하다.

## 생성
벡터공간 $V/F$와 $S \subseteq V$가 있을 때, $S$의 `생성(span)`이란 다음과 같이 정의한다.
$$ \text{span}(S) = \lang S \rang  := \left \{ \sum_{k=1}^{n}a_kv_k \; \Big\vert \; a_i \in F, v_i \in S \right \} $$

즉, $\text{span}(S)$란 $S$의 원소들의 선형결합으로 표현되는 집합이다. 이 때, $\displaystyle \sum_{k=1}^{n}a_kv_k$은 유한합이다. 

또한, $\text{span}(\empty) = \{ 0_V \}$로 정의한다.

### 명제1
벡터공간 $V/F$가 있을 때 다음을 증명하여라.

$$S \subseteq V \Rightarrow span(S) \subseteq V $$

**proof**

벡터공간은 $+, \cdot$ 연산에 닫혀있기 때문에 $V$안의 원소들간의 $+, \cdot$연산으로 이루어진 생성의 결과는 $V$의 원소가 된다. $\quad {_\blacksquare}$

### 명제2
벡터공간 $V/F$와 $S \subseteq V$가 있을 때, $span(V) = V$를 증명하여라.

**proof**

[$span(V) \subseteq V$]

$V$는 $V$의 부분집합이기 때문에 명제1에 의해 증명된다. $\quad {_\blacksquare}$

[$V \subseteq span(V)$]

$$ \begin{aligned} & v_j \in V \\ \Rightarrow \enspace & v_j = \sum_{k=1}^{n} a_kv_k, \quad \left( a_k = \begin{cases} 1 &  k=j \\ 0 & k \neq j \end{cases} \right) \\ \Rightarrow \enspace & v_j \in span(V) \quad {_\blacksquare} \end{aligned}   $$

#### 참고
$V$의 부분집합으로 $S=V$를 잡게 되면 $\text{span}(S) = \text{span}(V) = V$가 된다. 즉, $V$의 부분집합중 생성을 통해 $V$를 만들어내는 부분집합이 반드시 존재한다.


### 명제3
벡터공간 $V/F$와 $S \subseteq V$가 있을 때, $\text{span}(S)$가 벡터공간임을 증명하여라.

**proof**  

[기본 연산 법칙]  
벡터 공간의 부분집합과 연산을 그대로 사용하기 때문에 교환법칙 분배법칙등 $F-$가군의 성질들이 전부 성립한다. $\quad {_\blacksquare}$

[연산에 닫힘]  
$s_1, s_2 \in span(S), \enspace a \in F$가 있을 때 $as_1 + s_2 \in \text{span}(S)$이 성립한다. $\quad {_\blacksquare}$

[$+$연산 항등원의 존재성]  
모든 계수를 $0_F$로 두면, $0_V$가 된다. $\quad {_\blacksquare}$

[$+$연산 역원의 존재성]  
scalar multiplication이 정의되어 있음으로 환의 명제2에 의해 역원이 항상 존재한다. $\quad {_\blacksquare}$

### 명제4
벡터공간 $V/F$와 $S \subseteq V$과 $H := \{ W \enspace | \enspace S \subseteq W \land W \le V \}$가 있을 때, 다음을 증명하여라.
$$ \text{span}(S)=\bigcap H $$

**proof**

$S =\{ v_1, \cdots, v_n \}$이라 하자.

[$\text{span}(S) \subseteq \bigcap H$]  
$v \in \text{span}(S)$과 $H_i \in H$에 대해,

$$ \begin{aligned} & v = a_1v_1+ \cdots + a_nv_n \\  \Rightarrow \enspace & v \in H_i \quad (\because S \subseteq H_i \land H_i \text { is closed under +,} \cdot)  \\ \Rightarrow \enspace & v \in \bigcap H_i \end{aligned}  $$

[$\bigcap H \subseteq \text{span}(S)$]  
$$ \begin{aligned} & S \subseteq \text{span}(S) \land \text{span}(S) \le V \\ \Rightarrow \enspace & \text{span}(S) \in H \quad {_\blacksquare} \end{aligned} $$

#### 참고
 $span(W)$는 $W$를 포함하고 있는 $V$의 부분공간중에 가장 작은 부분공간이다.

## 선형 독립 집합
벡터공간 $V/F$와  $S \subseteq V$가 있을 때, $S$가 다음을 만족할경우 `선형 독립 집합(linearly independent set)`라고 한다.

$a \in F, S = \{ v_1, \cdots , v_n \}$ 일 때,

$$ \sum_{k=1}^{n}a_k v_k = 0_V \Rightarrow \forall a_k=0_F $$ 

$0_V \equiv e_{(V,+)}, 0_F \equiv e_{(F,+)}$이다.

그리고 선형 독립 집합이 아닌 집합을 `선형 종속 집합(linear dependent set)`이라고 한다.

### 참고1
선형 종속 집합 $S = \{ v_1, \cdots , v_n \} \subseteq V$가 있다면 다음을 만족한다.

$$\exist \{ a_1, \cdots a_n \} \quad s.t. \quad \sum_{k=1}^{n}a_k v_k = 0_V \land \{ a_1, \cdots a_n \}  \neq \{ 0_F, \cdots, 0_F \} $$

이 때, $a_1 \neq 0_F$이라고 가정하면 다음 관계식이 성립한다.
$$  v_1 = - a_1^{-1}\sum_{k=2}^{n} a_k v_k $$

즉, $v_1$은 $S$에 속하는 다른 원소들의 선형결합으로 표현이 가능하다.

### 참고2
$v \in V- \{0_V\}$에 대해 $\beta=\{v\}$면 $\beta$는 선형 독립 집합이다.


## 기저
벡터공간 $V/F$와 $\beta \subseteq V$가 있을 때, `기저(basis)`란 다음을 만족하는 부분집합이다.

$$ \beta \text{ is linearly independent set} \land span(\beta) = V $$

### 명제1
벡터공간 $V/F$와 선형 독립 집합 $S \subseteq V$가 있을 때, 집합 $F$를 다음과 같이 정의하자.

$$F := \{ A \subseteq V | S \subseteq A \land A \text{ is linearly independent}\}$$ 

이 때, $(F,\subseteq)$가 극대원소 $M$을 갖음을 증명하여라.

**Proof**  
$S \in F$임으로 $F \neq \empty$이고 $(F,\subseteq)$은 부분순서집합이다. 

$(F,\subseteq)$의 임의의 사슬 $C_i = \{ A_{i1}, \cdots, A_{in} \} \subseteq F$에 대해, $C$는 전순서집합임으로 `일반성을 잃지 않고(without loss of generality, WLOG)` $A_{i1} \subseteq \cdots \subseteq A_{in}$라 가정할 수 있다. 따라서 $C_i$는 항상 상계 $A_{in}$을 갖는다.

부분순서집합 $(F,\subseteq)$의 모든 사슬이 상계를 갖음으로, `초른의 보조정리(Zorn's lemma)`에 의해 $F$는 극대원소 $M$을 갖는다. $\quad {_ \blacksquare}$

### 명제2
정리 1의 극대원소 $M$이 $span(M)=V$을 만족함을 증명하여라.

**Proof**

$$ \begin{aligned} & V \neq span(M) \\ \Leftrightarrow \enspace & V - span(M) \neq \empty \\ \Leftrightarrow \enspace & \exist v \in V - span(M), \quad v \neq 0_V \\ \Rightarrow \enspace &  M \cup \{v\} \in F \enspace \land \enspace M \subseteq M \cup \{v\} \\ \Rightarrow \enspace & \Rightarrow \!\! \Leftarrow \text{maximality of } M \quad {_\blacksquare} \end{aligned} $$

### 명제3 (기저의 존재 정리)
모든 벡터공간 $V/F$이 기저를 갖음을 증명하여라.

**Proof** 

$V = \{ 0_V \}$인 경우 자명하게 $\beta = \emptyset$이다.

$V \neq \{ 0_V \}$인 경우  $\exist v \in V - \{ 0_V \}$이고 따라서 집합 $S = \{ av | a \in F \}$는 $V$의 선형 독립 집합이다. 

이 때, 명제1,2에 의해 $S \subseteq M$이고 $V = span(M)$인 선형 독립 집합 $M$이 존재한다.

따라서 $M$은 $V/F$의 기저가 된다. $\quad {_\blacksquare}$

#### 참고

1. 기저는 극대 선형 독립 집합이다.
2. 기저의 존재성은 초른의 보조정리에 의존한다.
3. 공리(초른의 보조정리)에 의해 기저의 존재성을 보장했을 뿐 기저가 무엇인지는 알 수 없다.
4. 기저의 유일성은 보장되지 않기 때문에 기저는 여러개일 수 있다.

### 명제4
벡터공간 $V/F$와 기저 $\beta_1,\beta_2$가 있을 때 $|\beta_1| = |\beta_2|$임을 증명하여라.

**proof**

$|\beta_1| \le |\beta_2|$라 하자.

그러면 함수 $f: \beta_1 \rightarrow \beta_2$는 단사함수이지만 전사함수는 아닌 함수가 존재한다.

이 경우 $f(\beta_1) \subset \beta_2$이다.

$\exist v_1 \in \beta_2 - f(\beta_1)$

Since $\beta_1, \beta_2$ are both maximal, it is contradiction.

`(미완성)`

### 명제5
벡터공간 $V / \mathbb F$와 기저 $\beta = \{ \beta_1, \cdots, \beta_n \}$가 있을 때, $U = \text{span}(\{\beta_1, \cdots, \beta_k \}), W = \text{span}(\{ \beta_{k+1}, \cdots \beta_n \})$라 하자.

 $V = U \oplus W$임을 증명하여라.

**Proof**

[$V \subseteq U \oplus W$]  
$$ \begin{aligned} & v \in V \\ \Rightarrow \enspace & v = a_1 \beta_1 + \cdots + a_k \beta_k + a_{k+1} \beta_{k+1} + \cdots + a_n \beta_n \\ \Rightarrow \enspace & v = u + w \\ \Rightarrow \enspace & v \in U \oplus W  \quad {_\blacksquare} \end{aligned}$$

[$U \oplus W \subseteq V$]  
$$ \begin{aligned} & x \in U \oplus W \\ \Rightarrow \enspace & x = a_1 \beta_1 + \cdots + a_k \beta_k + a_{k+1} \beta_{k+1} + \cdots + a_n \beta_n \\ \Rightarrow \enspace & x \in V  \quad {_\blacksquare} \end{aligned}$$

## 차원
벡터공간 $V/ \mathbb F$의 `차원(dimension)`은 기저 `집합의 크기(cardinality)`이다.

만약 $\dim(V) < \infty$이면 $V$를 유한 차원 벡터 공간이라고 하고 아니면 $V$를 무한 차원 벡터 공간이라고 한다.

### 명제1
유한차원 벡터공간 $V/ \mathbb F$와 subspace $S \le V$가 있을 때, 다음을 증명하여라.
$$ \dim(S) = \dim(V) \Rightarrow S = V $$

**Proof**

$S$의 기저를 $\beta$라 하자. $\text{span}(\beta) = S$이다.

$S \le V$임으로 $\beta \subset V$이고 따라서 $\beta$는 $V$의 기저이다.  $\text{span}(\beta) = V$이다.



## 행렬과 군
행렬 $A \in F^{m \times n}$, $B \in F^{n \times r}$이 있을 때, 행렬 방정식 $AX=B$를 풀어보자.

만약에 어떤 행렬 집합 $G$에 군 구조가 있고 $A \in G$면 군 구조의 역원 개념을 이용해 $X = A^{-1}B$이다.

군 구조를 갖는 $G$를 찾기 위해 다음의 대수적 구조를 생각해보자.

$$ G := ( \{ M \in F^{m \times n} \} , \times ) $$

$A,B \in G$에 대해, $B = A^{-1}$이려면 $AB = BA$여야 함으로 $m=n$이어야 한다.

따라서 $G$를 다음과 같이 축소시켜 보자.

$$ G := ( \{ M \in F^{n \times n} \} , \times ) $$

이제, $\delta_{ij} = \sum_{k=1}^n a_{ik}b_{kj}$를 만족해야 한다.

$b_{kj} := M_{jk} = M_{kj}^T$로 가정하면 `라플라스 전개(Laplace expansion)`에 의해 다음이 성립한다. 
$$\sum_{k=1}^n a_{ik}b_{kj} = \sum_{k=1}^n a_{ik}M_{jk} = \begin{cases} \det(A) & i=j \\ 0 & i \neq j \end{cases}$$

따라서 $b_{kj} = \frac{1}{\det(A)} M_{kj}^T$이면 $\sum_{k=1}^n a_{ik}b_{kj} = \delta_{ij}$이다.

이 때, `고전적 수반 행렬(adjugate matrix)` $\text{adj}(A) \in F^{n \times n}$은 $\text{adj}(A)_{ij} = M_{ij}^T$로 정의된다.

고전적 수반 행렬을 이용하면 역행렬은 다음과 같이 표현된다.

$$ A^{-1} = \frac{1}{\det(A)} \text{adj}(A) $$

따라서 $A^{-1}$가 정의되기 위해서는 $\det(A) \neq 0$이어야 한다. 

결론적으로 군 구조가 되기 위해서는 다음과 같아야 한다.

$$ G := ( \{ M \in F^{n \times n} | \det(M) \neq 0 \} , \times ) $$

### 참고1

$$ A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}, \quad \det(A) = ad - bc $$

$\det(A)$는 $A$의 행 벡터들에 의해 생성되는 부호있는 부피이다.

따라서 $\det(A) = 0$이라는 말은 행 벡터들이 선형 독립이 아니라서 의미있는 부피(차원)을 만들어내지 못한다는 말이다.

#### 명제1
$\det(A) = \det(A^T)$

이로써 $\det(A)$가 열 벡터들에 의해 생성되는 부호있는 부피이기도 하다는것을 알 수 있다.

**proof**

#### 명제2
$\det(AB) = \det(A)\det(B)$

**proof**

### 라플라스 전개

$\det(A) = \sum _{k=1}^n a_{kj}M_{kj}$

### 명제1
$A \in F^{n \times n}$이 있을 때, 다음이 전부 동치임을 증명하여라.

1. $A$는 역행렬이 존재한다.
2. $AX = 0$의 해는 오직 자명해인 $X=0$만 가능하다.
3. $A$는 행동치(row equivalent)하다.
4. $AX=B$는 언제나 해를 갖는다.
5. $\det(A) \neq 0$
6. $\text{rank}(A)=n$이다.
7. $A$의 모든 행 벡터는 선형 독립이다.
8. $A$의 모든 열 벡터는 선형 독립이다.

## 기본행연산
다음의 연산들을 `기본행연산(elementary row operation)`이라 한다.

1. 행에 0이 아닌 상수를 곱한다.
2. 두 행을 바꾼다.
3. 한 행에 상수를 곱한뒤 다른 행에 더해준다.

기본행연산의 목표는 $A|I$형태에서 기본행연산만을 수행해서 $I|A^{-1}$을 만들어 $A^{-1}$을 찾아내는 것이다.







## 특성다항식(행렬)
$A \in \mathbb F^{n \times n}$가 있을 때, $\det(A - tI)$를 $A$의 특성다항식이라하고 $\varphi_A(t)$로 표기한다.

### 명제1
$A \in \mathbb F^{n \times n}$가 있을 때 다음을 증명하여라
$$\varphi_A(t) = (-1)^n(t^n + a_1t^{n-1} + \cdots + a_{n-1}t + a_n) \quad a_n =\begin{cases} -\mathrm{tr} (A) & i = 1  \\ (-1)^i\det(A) & i = 2 \cdots n \end{cases}$$

**Proof**

수학적 귀납법

어떤 선형변환이 주어졌을 때, 이를 간단하게 나타내는 방법

## 선형변환의 다양한 정의
벡터공간 $V/ \mathbb F$와 임의의 기저 $\beta$ 그리고 $T \in L(V,V)$가 있을 때, 행렬의 여러 개념들을 선형변환에서는 다음과 같이 정의한다.
$$ \det(T) := \det([T]_\beta) $$
$$ \mathrm{tr}(T) := \mathrm{tr}([T]_\beta) $$

### 보조정리1
$A,B \in \mathbb F^{n \times n}$가 $A \sim B$일 때, $\det(A) = \det(B)$임을 증명하여라.

**Proof**

$$ \det(A) = \det(P^{-1}BP) = \det(P^{-1})\det(B)\det(P) = \det({P^{-1}P})\det(B) = \det(B) \quad {_\blacksquare} $$

### 보조정리2
$A,B \in \mathbb F^{n \times n}$가 $A \sim B$일 때, $\mathrm{tr}(A) = \mathrm{tr}(B)$임을 증명하여라. 

**Proof**

$$ \mathrm{tr}(A) = \mathrm{tr}(P^{-1}BP) = \mathrm{tr}(PP^{-1}B) = \mathrm{tr}(B) \quad (\because \mathrm{tr}(AB) = \mathrm{tr}(BA)) \quad {_\blacksquare}  $$

### 명제1
벡터공간 $V/ \mathbb F$와 $T \in L(V,V)$가 있을 때, 선형변환의 determinant와 trace가 well-defined 됨을 증명하여라.

**Proof**

well-defined 되기 위해서는 기저의 선택에 관계없이 일정함을 보이면 된다. $V$의 두 기저를 $\beta,\gamma$라 하자. 그러면 $[T]_\beta \sim [T]_\gamma$임으로 보조정리1,2 에 의해 증명이 끝난다. $\quad {_\blacksquare}$

### 명제2
벡터공간 $V/ \mathbb F$와 $T \in L(V,V)$가 있을 때, 다음을 증명하여라.
$$ \lambda \in \mathbb{F} \text{ is eigen value of } T \Leftrightarrow \det(T - \lambda id) = 0 $$

**Proof**

[$\Rightarrow$]  
$\beta$를 $V$의 기저라고 하자.
$$ \begin{aligned} & \exist v \in V - \{ 0_V \} \quad s.t. \quad (T - \lambda id)(v) = 0_V \\ \Rightarrow \enspace & [T - \lambda id]_\beta [v]_\beta = 0_F \\ \Rightarrow \enspace & \det( [T - \lambda id]_\beta ) = 0 \quad (\because [v]_\beta \neq 0_F) \quad {_\blacksquare}  \end{aligned} $$
$$ \text{Where, } \beta \text{ is a any basis of } V $$

[$\Leftarrow$]  
$$ \begin{aligned} & \det(T-\lambda id) = 0 \\ \Rightarrow \enspace &  \det([T - \lambda id]_\beta) = 0 \\ \Rightarrow \enspace & \exist v \in V - \{ 0_V \} \quad s.t. \quad [T - \lambda id]_\beta [v]_\beta = 0_F \\ \Rightarrow \enspace & [T]_\beta [v]_\beta = \lambda [v]_\beta \\ \Rightarrow \enspace & T(v) = \lambda v \quad {_\blacksquare}  \end{aligned}  $$

> $\det(A)=0 \Rightarrow \exist x \neq 0 \quad s.t. \quad Ax = 0$를 증명하여라.

## 특성다항식(선형변환)
벡터공간 $V/\mathbb F$와 $T \in L(V,V)$가 있을 때, $T$의 특성다항식은 다음과 같이 정의된다.
$$ \varphi_T(t) = \det(T - tid) $$

특성다항식의 근이 고유값이 된다.

---

$\lambda_1, \cdots, \lambda_k$

$$\exist v \in V - \{0\} \quad s.t. \quad (T - \lambda id)(v) = 0 \Rightarrow [T - \lambda id]_\beta [v]_\beta = 0$$

# 대칭행렬
symmetric matrix일 때, eigenvector는 서로 수직한다.

> 참고  
> [book] (Lai et al) Introduction to Continuum Mechanics Chapter 2.23

# Definite Matrix
$\mathbf M \in Mat_{nn}(\R)$라 할 때, 다음을 만족하는 행렬을 `positive-definite`라고 한다.
$$ \mathbf x \in \R^n - \{ 0 \} \Rightarrow \mathbf x^T \mathbf M \mathbf x > 0 $$

### 명제1
$\mathbf M \in Mat_{nn}(\R)$라 할 때, 다음을 증명하여라.
$$ \mathbf M \text{ is positive definite} \Leftrightarrow \text{all eigenvalues are positive} $$

> 참고  
> [Definite Matrix - Wiki](https://en.wikipedia.org/wiki/Definite_matrix)

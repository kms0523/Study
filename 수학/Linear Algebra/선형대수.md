## sum
유한차원 벡터공간 $V / \mathbb F$와 $U,W \le V$가 있을 때, $U$와 $W$의 `합(sum)` $U+W$는 다음과 같이 정의된다.
$$ U+W := \{ u + w \enspace | \enspace u \in U, w \in W \} $$

### 명제1
유한차원 벡터공간 $V / \mathbb F$와 $U,W \le V$가 있을 때, $U+W \le V$임을 증명하여라.

**Proof**

[기본 연산 법칙]  
z벡터 공간의 부분집합과 연산을 그대로 사용하기 때문에 교환법칙 분배법칙등이 $F-$가군의 성질들이 전부 성립한다. 

[연산에 닫힘]  
$T_1, T_2 \in L(V,W)$, $a \in \Bbb F$라 하자.

$v_1,v_2 \in V$, $b \in \mathbb{F}$가 있을 때 다음이 성립한다.
$$ \begin{aligned} (aT_1 + T_2)(bv_1 + v_2) &= aT_1(bv_1 + v_2) + T_2(bv_1 + v_2) \\ &= abT_1(v_1) + bT_2(v_1) + aT_1(v_2) + T_2(v_2) \\ &= b(aT_1+T_2)(v_1) + (aT_1+T_2)(v_2) \end{aligned}  $$

따라서, $(aT_1 + T_2)$도 $V$에서 $V$로 가는 선형변환임으로 연산에 닫혀있다. $\quad {_\blacksquare}$

[$+$연산 항등원의 존재성]  
영함수가 다음과 같이 정의되어 있다고 하자.
$$ T_0 : V \rightarrow W \quad s.t. \quad v \mapsto 0_W $$



### 명제2
유한차원 벡터공간 $V / \mathbb F$와 $U,W \le V$가 있을 때, $U \le U+W$와 $W \le U+W$임을 증명하여라.

## direct sum
유한차원 벡터공간 $V / \mathbb F$와 $U,W \le V$가 있을 때, $U \cap W = \{ 0_V \}$면 $U$와 $W$의 `direct sum` $U \oplus W$는 다음과 같이 정의된다.
$$ U \oplus W := \{ u + w \enspace | \enspace u \in U, w \in W \} $$

direct sum은 여러항으로 다음과 같이 확장이 가능하다.

$U_i \le V \enspace i = 1, \cdots, k$가 있을 때, $i = 1, \cdots, k$에 대해 $U_i \cap \bigcup_{\begin{subarray}{l} j = 1 \\ j \neq i \end{subarray}}^k U_j = \{ 0_V \}$면 여러항의 direct sum은 다음과 같이 정의 된다.

$$ \bigoplus_{i=1}^k U_i = \{ u_1 + \cdots + u_k  \enspace | \enspace u_i \in U_i \enspace i = 1, \cdots, k \} $$

### 명제1
유한차원 벡터공간 $V / \mathbb F$와 $W_1, \cdots, W_n \le V$가 있을 때, 다음을 증명하여라.
$$V = W_1 \oplus \cdots \oplus W_n \Rightarrow v \in V \Rightarrow \exist! w_i \in W_i \quad s.t. \quad  v = w_1 + \cdots + w_n$$

**Proof**

$V = W_1 \oplus \cdots \oplus W_n$임으로 $\exist w_i \in W_i \quad s.t \quad v = w_1 + \cdots + w_n$는 자명하다. 

$\exist q_i \in W_i \quad s.t \quad v = q_1 + \cdots + q_n$라 하자. 두 표현식을 빼면 다음과 같다.
$$ 0_V = (w_1 - q_1) + \cdots + (w_n - q_n) $$

$W_i < V$임으로 $w \in W_i$면 $w^{-1} \in W_i$이다. 또한 $W_i \cap W_j = \{ 0_V \}$임으로 $w^{-1} \notin W_j$이다. 즉, $(w_2 - q_2) + \cdots + (w_n - q_n)$은 $(w_1 - q_1)$의 역원이 될 수 없고 식을 만족하기 위해서는 $(w_1 - q_1) = 0_V$이어야 한다. 마찬가지로 $w_i - q_i = 0_V$임으로 $w_i = q_i$이다. 즉, $v = w_1 + \cdots + w_n$를 만족하는 $w_i \in W_i$는 유일하다.

## 생성
벡터공간 $V/F$와 $S \subseteq V$가 있을 때, $S$의 `생성(span)`이란 다음과 같이 정의한다.
$$ \text{span}(S) = \lang S \rang  := \left \{ \sum_{k=1}^{n}a_kv_k \; \Big\vert \; a_i \in F, v_i \in S \right \} $$

즉, $\text{span}(S)$란 $S$의 원소들의 선형결합으로 표현되는 집합이다. 이 때, $\displaystyle \sum_{k=1}^{n}a_kv_k$은 유한합이다. 

또한, $\text{span}(\empty) = \{ 0_V \}$로 정의한다.

### 명제1
벡터공간 $V/F$가 있을 때 다음을 증명하여라.

$$S \subseteq V \Rightarrow span(S) \subseteq V $$

**proof**

벡터공간은 $+, \cdot$ 연산에 닫혀있기 때문에 $V$안의 원소들간의 $+, \cdot$연산으로 이루어진 생성의 결과는 $V$의 원소가 된다. $\quad {_\blacksquare}$

### 명제2
벡터공간 $V/F$와 $S \subseteq V$가 있을 때, $span(V) = V$를 증명하여라.

**proof**

[$span(V) \subseteq V$]

$V$는 $V$의 부분집합이기 때문에 명제1에 의해 증명된다. $\quad {_\blacksquare}$

[$V \subseteq span(V)$]

$$ \begin{aligned} & v_j \in V \\ \Rightarrow \enspace & v_j = \sum_{k=1}^{n} a_kv_k, \quad \left( a_k = \begin{cases} 1 &  k=j \\ 0 & k \neq j \end{cases} \right) \\ \Rightarrow \enspace & v_j \in span(V) \quad {_\blacksquare} \end{aligned}   $$

#### 참고
$V$의 부분집합으로 $S=V$를 잡게 되면 $\text{span}(S) = \text{span}(V) = V$가 된다. 즉, $V$의 부분집합중 생성을 통해 $V$를 만들어내는 부분집합이 반드시 존재한다.


### 명제3
벡터공간 $V/F$와 $S \subseteq V$가 있을 때, $\text{span}(S)$가 벡터공간임을 증명하여라.

**proof**  

[기본 연산 법칙]  
벡터 공간의 부분집합과 연산을 그대로 사용하기 때문에 교환법칙 분배법칙등 $F-$가군의 성질들이 전부 성립한다. $\quad {_\blacksquare}$

[연산에 닫힘]  
$s_1, s_2 \in span(S), \enspace a \in F$가 있을 때 $as_1 + s_2 \in \text{span}(S)$이 성립한다. $\quad {_\blacksquare}$

[$+$연산 항등원의 존재성]  
모든 계수를 $0_F$로 두면, $0_V$가 된다. $\quad {_\blacksquare}$

[$+$연산 역원의 존재성]  
scalar multiplication이 정의되어 있음으로 환의 명제2에 의해 역원이 항상 존재한다. $\quad {_\blacksquare}$

### 명제4
벡터공간 $V/F$와 $S \subseteq V$과 $H := \{ W \enspace | \enspace S \subseteq W \land W \le V \}$가 있을 때, 다음을 증명하여라.
$$ \text{span}(S)=\bigcap H $$

**proof**

$S =\{ v_1, \cdots, v_n \}$이라 하자.

[$\text{span}(S) \subseteq \bigcap H$]  
$v \in \text{span}(S)$과 $H_i \in H$에 대해,

$$ \begin{aligned} & v = a_1v_1+ \cdots + a_nv_n \\  \Rightarrow \enspace & v \in H_i \quad (\because S \subseteq H_i \land H_i \text { is closed under +,} \cdot)  \\ \Rightarrow \enspace & v \in \bigcap H_i \end{aligned}  $$

[$\bigcap H \subseteq \text{span}(S)$]  
$$ \begin{aligned} & S \subseteq \text{span}(S) \land \text{span}(S) \le V \\ \Rightarrow \enspace & \text{span}(S) \in H \quad {_\blacksquare} \end{aligned} $$

#### 참고
 $span(W)$는 $W$를 포함하고 있는 $V$의 부분공간중에 가장 작은 부분공간이다.

## 선형 독립 집합
벡터공간 $V/F$와  $S \subseteq V$가 있을 때, $S$가 다음을 만족할경우 `선형 독립 집합(linearly independent set)`라고 한다.

$a \in F, S = \{ v_1, \cdots , v_n \}$ 일 때,

$$ \sum_{k=1}^{n}a_k v_k = 0_V \Rightarrow \forall a_k=0_F $$ 

$0_V \equiv e_{(V,+)}, 0_F \equiv e_{(F,+)}$이다.

그리고 선형 독립 집합이 아닌 집합을 `선형 종속 집합(linear dependent set)`이라고 한다.

### 참고1
선형 종속 집합 $S = \{ v_1, \cdots , v_n \} \subseteq V$가 있다면 다음을 만족한다.

$$\exist \{ a_1, \cdots a_n \} \quad s.t. \quad \sum_{k=1}^{n}a_k v_k = 0_V \land \{ a_1, \cdots a_n \}  \neq \{ 0_F, \cdots, 0_F \} $$

이 때, $a_1 \neq 0_F$이라고 가정하면 다음 관계식이 성립한다.
$$  v_1 = - a_1^{-1}\sum_{k=2}^{n} a_k v_k $$

즉, $v_1$은 $S$에 속하는 다른 원소들의 선형결합으로 표현이 가능하다.

### 참고2
$v \in V- \{0_V\}$에 대해 $\beta=\{v\}$면 $\beta$는 선형 독립 집합이다.


## 기저
벡터공간 $V/F$와 $\beta \subseteq V$가 있을 때, `기저(basis)`란 다음을 만족하는 부분집합이다.

$$ \beta \text{ is linearly independent set} \land span(\beta) = V $$

### 명제1
벡터공간 $V/F$와 선형 독립 집합 $S \subseteq V$가 있을 때, 집합 $F$를 다음과 같이 정의하자.

$$F := \{ A \subseteq V | S \subseteq A \land A \text{ is linearly independent}\}$$ 

이 때, $(F,\subseteq)$가 극대원소 $M$을 갖음을 증명하여라.

**Proof**  
$S \in F$임으로 $F \neq \empty$이고 $(F,\subseteq)$은 부분순서집합이다. 

$(F,\subseteq)$의 임의의 사슬 $C_i = \{ A_{i1}, \cdots, A_{in} \} \subseteq F$에 대해, $C$는 전순서집합임으로 `일반성을 잃지 않고(without loss of generality, WLOG)` $A_{i1} \subseteq \cdots \subseteq A_{in}$라 가정할 수 있다. 따라서 $C_i$는 항상 상계 $A_{in}$을 갖는다.

부분순서집합 $(F,\subseteq)$의 모든 사슬이 상계를 갖음으로, `초른의 보조정리(Zorn's lemma)`에 의해 $F$는 극대원소 $M$을 갖는다. $\quad {_ \blacksquare}$

### 명제2
정리 1의 극대원소 $M$이 $span(M)=V$을 만족함을 증명하여라.

**Proof**

$$ \begin{aligned} & V \neq span(M) \\ \Leftrightarrow \enspace & V - span(M) \neq \empty \\ \Leftrightarrow \enspace & \exist v \in V - span(M), \quad v \neq 0_V \\ \Rightarrow \enspace &  M \cup \{v\} \in F \enspace \land \enspace M \subseteq M \cup \{v\} \\ \Rightarrow \enspace & \Rightarrow \!\! \Leftarrow \text{maximality of } M \quad {_\blacksquare} \end{aligned} $$

### 명제3 (기저의 존재 정리)
모든 벡터공간 $V/F$이 기저를 갖음을 증명하여라.

**Proof** 

$V = \{ 0_V \}$인 경우 자명하게 $\beta = \emptyset$이다.

$V \neq \{ 0_V \}$인 경우  $\exist v \in V - \{ 0_V \}$이고 따라서 집합 $S = \{ av | a \in F \}$는 $V$의 선형 독립 집합이다. 

이 때, 명제1,2에 의해 $S \subseteq M$이고 $V = span(M)$인 선형 독립 집합 $M$이 존재한다.

따라서 $M$은 $V/F$의 기저가 된다. $\quad {_\blacksquare}$

#### 참고

1. 기저는 극대 선형 독립 집합이다.
2. 기저의 존재성은 초른의 보조정리에 의존한다.
3. 공리(초른의 보조정리)에 의해 기저의 존재성을 보장했을 뿐 기저가 무엇인지는 알 수 없다.
4. 기저의 유일성은 보장되지 않기 때문에 기저는 여러개일 수 있다.

### 명제4
벡터공간 $V/F$와 기저 $\beta_1,\beta_2$가 있을 때 $|\beta_1| = |\beta_2|$임을 증명하여라.

**proof**

$|\beta_1| \le |\beta_2|$라 하자.

그러면 함수 $f: \beta_1 \rightarrow \beta_2$는 단사함수이지만 전사함수는 아닌 함수가 존재한다.

이 경우 $f(\beta_1) \subset \beta_2$이다.

$\exist v_1 \in \beta_2 - f(\beta_1)$

Since $\beta_1, \beta_2$ are both maximal, it is contradiction.

`(미완성)`

### 명제5
벡터공간 $V / \mathbb F$와 기저 $\beta = \{ \beta_1, \cdots, \beta_n \}$가 있을 때, $U = \text{span}(\{\beta_1, \cdots, \beta_k \}), W = \text{span}(\{ \beta_{k+1}, \cdots \beta_n \})$라 하자.

 $V = U \oplus W$임을 증명하여라.

**Proof**

[$V \subseteq U \oplus W$]  
$$ \begin{aligned} & v \in V \\ \Rightarrow \enspace & v = a_1 \beta_1 + \cdots + a_k \beta_k + a_{k+1} \beta_{k+1} + \cdots + a_n \beta_n \\ \Rightarrow \enspace & v = u + w \\ \Rightarrow \enspace & v \in U \oplus W  \quad {_\blacksquare} \end{aligned}$$

[$U \oplus W \subseteq V$]  
$$ \begin{aligned} & x \in U \oplus W \\ \Rightarrow \enspace & x = a_1 \beta_1 + \cdots + a_k \beta_k + a_{k+1} \beta_{k+1} + \cdots + a_n \beta_n \\ \Rightarrow \enspace & x \in V  \quad {_\blacksquare} \end{aligned}$$

## 차원
벡터공간 $V/ \mathbb F$의 `차원(dimension)`은 기저 `집합의 크기(cardinality)`이다.

만약 $\dim(V) < \infty$이면 $V$를 유한 차원 벡터 공간이라고 하고 아니면 $V$를 무한 차원 벡터 공간이라고 한다.

### 명제1
유한차원 벡터공간 $V/ \mathbb F$와 subspace $S \le V$가 있을 때, 다음을 증명하여라.
$$ \dim(S) = \dim(V) \Rightarrow S = V $$

**Proof**

$S$의 기저를 $\beta$라 하자. $\text{span}(\beta) = S$이다.

$S \le V$임으로 $\beta \subset V$이고 따라서 $\beta$는 $V$의 기저이다.  $\text{span}(\beta) = V$이다.


# 선형 변환
벡터 공간 $V,W/F$와 함수 $\Phi:V \rightarrow W$에 대해, `선형 변환(linear transformation)` 혹은 `선형 사상(linear map)`은 다음을 만족하는 $\Phi$이다.

$$ v_1,v_2 \in V, a \in F \Rightarrow \Phi(av_1+v_2)=a\Phi(v_1)+\Phi(v_2)$$  

만약, $W = \mathbb F$이면 `linear form`이라고 한다.

linear map은 벡터 공간의 연산 및 관계를 보존하는 함수로 `vector space homomorphism`이다.

그리고 $V \rightarrow W$인 모든 linear map들을 모은 집합을 $L(V; W)$라 표기한다.

### 명제1
유한 차원 벡터공간 $V,W,Z/F$와 $T_1 \in L(V,W), T_2\in L(W,Z)$가 있을 때 $T_2 \circ T_1 \in L(V,Z)$를 증명하여라.

**proof**  
$v_1,v_2 \in V$과 $a \in F$에 대해,

$$ \begin{aligned} (T_2 \circ T_1)(av_1 + v_2) & = T_2(T_1(av_1 +v_2)) \\ & = T_2(aT_1(v_1) +T_1(v_2)) \\ & = aT_2(T_1(v_1)) + T_2(T_1(v_2)) \\ & = a(T_2 \circ T_1)(v_1) + (T_2 \circ T_1)(v_2) \quad {_\blacksquare}  \end{aligned} $$

### 명제2
두 벡터공간 $V,W / \mathbb F$가 있을 때, $L(V; W)$에 다음과 같은 연산을 주면 $\mathbb F$위의 벡터공간임을 보여라.
$$ \begin{aligned} + : & L(V,W) \times L(V,W) \rightarrow L(V,W) \quad s.t. \quad T_1 + T_2 \mapsto (T_1 + T_2) \\ & \text {satisfying} \quad (T_1 + T_2)(v) = T_1(v) + T_2 (v) \\ \cdot : & \mathbb F \times L(V,W) \rightarrow L(V,W) \quad s.t. \quad a \cdot T \mapsto (aT) \\ & \text {satisfying} \quad (aT)(v) = aT(v) \end{aligned}  $$

**Proof**

[기본 연산 법칙]  
벡터 공간의 부분집합과 연산을 그대로 사용하기 때문에 교환법칙 분배법칙등 $F-$가군의 성질들이 전부 성립한다. 

[연산에 닫힘]  
$T_1, T_2 \in L(V,W)$, $a \in \Bbb F$라 하자.

$v_1,v_2 \in V$, $b \in \mathbb{F}$가 있을 때 다음이 성립한다.
$$ \begin{aligned} (aT_1 + T_2)(bv_1 + v_2) &= aT_1(bv_1 + v_2) + T_2(bv_1 + v_2) \\ &= abT_1(v_1) + bT_2(v_1) + aT_1(v_2) + T_2(v_2) \\ &= b(aT_1+T_2)(v_1) + (aT_1+T_2)(v_2) \end{aligned}  $$

따라서, $aT_1 + T_2 \in L(V,W)$임으로 연산에 닫혀있다. $\quad {_\blacksquare}$

[$+$연산 항등원의 존재성]  
함수가 다음과 같이 정의되어 있다고 하자.
$$ T_0 : V \rightarrow W \quad s.t. \quad v \mapsto 0_W $$

자명하게 $T_0 \in L(V,W)$이고 $T_0$는 $+$에 대해 항등원이다.

[$+$연산 역원의 존재성]  
상수곱이 정의되어 있음으로 환의 명제2에 의해 역원이 존재한다. 

### 명제3
각 각 차원이 $n,m$인 두 벡터공간 $V,W / \mathbb F$가 있을 때, 다음을 증명하여라.
$$ \dim(L(V;W)) = mn $$

**Proof**

$V,W$의 기저를 각 각 $\beta, \gamma$라 할 때, 함수 $f_{ij}$를 다음과 같이 정의하자.
$$f_{ij} : V \rightarrow W \quad s.t. \quad \beta_k \mapsto \begin{cases} 0 & \text{if} \enspace k \neq j \\ \gamma_i & \text{if} \enspace k = j \end{cases} \substack{}\enspace i=1, \cdots, m, \enspace j = 1, \cdots, n $$

[$f_{ij} \in L(V;W)$]  
$c \in \mathbb F, \enspace v_1 = a^i\beta_i, \enspace v_2 = b^i \beta_i \in V$가 있을 때, 다음이 성립한다.
$$ \begin{aligned} f_{ij}(cv_1 + v_2) = ca^j + b^j = cf_{ij}(v_1) + f_{ij}(v_2) \end{aligned} $$

[$f_{ij}$ are linearly independent]  
$c^{ij}f_{ij} = 0_{L(V;W)}$라 하자.

$v = a^i\beta_i \in V$에 대해 다음이 성립한다.
$$ c^{ij}f_{ij}(v) =  $$

## Kernel
유한 차원 벡터 공간 $V,W / \mathbb F$와 $T \in L(V,W)$가 있을 때, 다음과 같이 정의된 집합을 $T$의 kernel이라고 한다.
$$ \ker(T) := \{ v \in V \enspace | \enspace T(v) = 0_W \} $$

### 명제1
유한 차원 벡터 공간 $V,W / \mathbb F$과 $T \in L(V,W)$가 있을 때, 다음을 증명하여라.
$$ \ker(T) \le V $$

**Proof**

[기본 연산 법칙]  
벡터 공간의 부분집합과 연산을 그대로 사용하기 때문에 교환법칙 분배법칙등 $F-$가군의 성질들이 전부 성립한다. 

[연산에 닫힘]  
$v_1, v_2 \in \ker(T)$, $a \in \Bbb F$가 있을 때, $T(av_1 + v_2) = aT(v_1) + T(v_2) = 0_W$임으로 $av_1 + v_2 \in \ker(T)$이고 연산에 닫혀있다.

[항등원의 존재성]  
명제1에 의해 항등원이 존재한다. 

[역원의 존재성]  
상수곱이 정의되어 있음으로 환의 명제2에 의해 역원이 존재한다. 

따라서 $\ker(T)$는 $V$의 부분벡터공간이다. $\quad {_\blacksquare}$

### 명제2
유한 차원 벡터 공간 $V,W / \mathbb F$과 $T \in L(V,W)$가 있을 때, 다음을 증명하여라.
$$ \ker(T) = \{ 0_V \} \Leftrightarrow T \text{ is injective} $$

**Proof1**

group monomorphism의 명제에 의해 성립한다.

**Proof2**

[$\Rightarrow$]  
$v_1, v_2 \in V$일 때, 다음이 성립한다.
$$ \begin{aligned} & T(v_1) = T(v_2) \\ \Rightarrow \enspace & T(v_1) - T(v_2) = T(v_2) - T(v_2) \\ \Rightarrow \enspace & T(v_1 - v_2) = 0_W \\ \Rightarrow \enspace & v_1 - v_2 = 0_V \\ \Rightarrow \enspace & v_1 = v_2 \end{aligned} $$

[$\Leftarrow$]  
$T(0_V) = T(0_F 0_V) = 0_F T(0_V) = 0_W$이고 $T$가 단사함수임으로 $\ker(T) = \{ 0_V \}$이다. $\quad {_\blacksquare}$

## Image
유한 차원 벡터 공간 $V,W / \mathbb F$와 $T \in L(V,W)$가 있을 때, 다음과 같이 정의된 집합을 $T$의 image이라고 한다.
$$ \text{img}(T) := \{ T(v) \in W \enspace | \enspace v \in V \} $$

$\text{img}(T)$는 $T(V)$로 쓰기도 한다.

### 명제1
유한 차원 벡터 공간 $V,W/F$과 $T \in L(V,W)$가 있을 때, $\mathrm{img}(T) \le W$를 증명하여라.

**Proof**

[기본 연산 법칙]  
벡터 공간의 부분집합과 연산을 그대로 사용하기 때문에 교환법칙 분배법칙등 $F-$가군의 성질들이 전부 성립한다. 

[연산에 닫힘]  
$w_1, w_2 \in \mathrm{img}(T)$, $a \in \Bbb F$가 있을 때, $\exist v_1,v_2 \quad s.t \quad w_1 = T(v_1), w_2 = T(v_2)$이다. 따라서 $aw_1 + w_2 = aT(v_1) + T(v_2) = T(av_1 + v_2)  \in \mathrm{img}(T)$임으로 연산에 닫혀있다.

[항등원의 존재성]  
$$ T(0_V) = T(0_F 0_V) = 0_F T(0_V) = 0_W $$

[역원의 존재성]  
scalar multiplication이 정의되어 있음으로 환의 명제2에 의해 역원이 존재한다. 

따라서 $\mathrm{img}(T)$는 $W$의 부분벡터공간이다. $\quad {_\blacksquare}$

## Dimension Theorem
벡터공간 $V,W / \mathbb F$와, $T \in L(V,W)$가 있을 때 다음을 증명하여라.
$$ \dim(V) = \text{nullity}(T) + \text{rank}(T) $$

**Proof1**

추상대수학에서 1st homorphism theorem을 통해 군 $G,H$와 group homomorphism인 $f : G \rightarrow H$가 있을 때, $G / \ker(f) \cong \text{img}(f)$임을 보였다. 이를 벡터공간으로 확장하면 다음과 같다.

벡터공간 $V,W / \mathbb F$와, $T \in L(V,W)$가 있을 때, $V / \ker(T) \cong \text{img}(T)$이다. 이를 통해 $\dim(V / \ker(T)) = \dim(\text{img}(T))$이고 정리하면 $\dim(V) = \text{nullity}(T) + \text{rank}(T)$이다.

**Proof2**

$V$의 기저를 $\beta$라 하고, $\ker(T)$의 기저를 $\beta_0$라고 하자. 그러면 $T(\beta - \beta_0)$는 $\text{img}(T)$의 기저가 됨으로 $\text{rank}(T) = \dim(V) - \text{nullity}(T)$가 된다.

### 명제1
유한 차원 벡터 공간 $V,W / \mathbb F$과 $T \in L(V,W)$가 있을 때, 다음을 증명하여라.
$$ \dim(V) = \dim(W) \land \ker(T) = \{ 0_V \} \Rightarrow T \text{ is bijective} $$

**Proof**

[injective]  
Kernel의 명제2에 의해 $T$는 injective이다.

[surjective]  
가정과 Dimension Theorem에 의해 다음이 성립한다.
$$ \dim(W) = \dim(V) = \text{nullity}(T) + \text{rank}(T) = \text{rank}(T) = \dim(\text{img}(T)) $$

$\text{img}(T) \le W$이고 $\dim(\text{img}(T)) = \dim(W)$임으로 차원의 명제1에 의해 $\text{img}(T) = W$이다. $\quad {_\blacksquare}$


## 벡터 공간 동형 사상  
벡터 공간 $V,W/F$과 $\Phi \in L(V,W)$에 대해 $\Phi^{-1}:W \rightarrow V \in L(W,V)$면 $\Phi$를 `벡터 공간 동형 사상(vector space isomorphism)`이라고 한다.

### 명제1  
유한 차원 벡터 공간 $V,W/F$와 $\Phi \in L(V,W)$가 있을 때 다음을 증명하여라.  

$$\Phi \text{ is bijective} \Rightarrow \Phi^{-1} \in L(W,V)$$

**proof**  
$\Phi$가 전단사 함수임으로 $\exist! \Phi^{-1}$이고 $v_1,v_2 \in V$에 대해 $\exist!w_1,w_2 \in W, \Phi(v_1)=w_1, \Phi(v_2)=w_2$이다.

$$\begin{aligned} & \Phi(av_1 + v_2) = aw_1 + w_2 \\ \Leftrightarrow \enspace & av_1 + v_2 = \Phi^{-1}(aw_1 + w_2) \\ \Leftrightarrow \enspace & \Phi^{-1}(aw_1 + w_2) = a\Phi^{-1}(w_1) + \Phi^{-1}(w_2) \quad {_\blacksquare}  \end{aligned} $$

### 명제2
유한 차원 벡터 공간 $V,W/F$, $V$의 기저 $\beta = \{ v_1, \cdots, v_n \}$ 그리고 벡터 공간 동형 사상 $\Phi:V \rightarrow W$이 있을 때, 다음을 증명하여라.

$$ R :=  \{ \Phi(v_1),\cdots,\Phi(v_n) \} \text { is a basis of } W$$

#### proof
[ proof of $R$ is linearly independent ]

$$\begin{aligned} & a_1\Phi(v_1)+\cdots+a_n\Phi(v_n) = 0_W \\ \Leftrightarrow \enspace & \Phi(a_1v_1+\cdots+a_nv_n) = \Phi(0_V) \\ \Rightarrow \enspace & a_1v_1 + \cdots + a_nv_n = 0_V \\ \Rightarrow \enspace & a_1= \cdots = a_n = 0_F \quad {_\blacksquare} \end{aligned} $$

[ proof of $span(R)=W$  ]

[ $span(R) \subseteq W$ ]

$R \subseteq W$ 임으로 생성의 명제1에 의해 증명된다. $\quad {_\blacksquare}$


[ $W \subseteq span(R)$ ]

$$ \begin{aligned} & w \in W, \quad \exists! v \in V \quad s.t \quad \Phi(v) = w \\ \Rightarrow \enspace & w = \Phi(a_1v_1 + \cdots + a_nv_n) = a_1\Phi(v_1)+\cdots+a_n\Phi(v_n) \\ \Rightarrow \enspace & w \in span(R) \quad {_\blacksquare} \end{aligned} $$


## 벡터 공간 동형  
유한 차원 벡터 공간 $V,W/ \mathbb F$와 벡터 공간 동형 사상 $\Phi:V \rightarrow W$가 있을 때, $V$와 $W$를 `벡터 공간 동형(vector space isomorphic)`이라고 하고 $V \overset{\Phi \;}{\cong} W$ 또는 $V \cong W$라고 표기한다.

### 명제1
유한 차원 벡터 공간 $V,W/F$가 있을 때, 다음을 증명하여라.

$$V \cong W \iff \dim(V)=\dim(W)$$

**Proof**  

[$\Rightarrow$]  
$V$의 기저 $\beta$와 vector space isomorphism $\Phi:V \rightarrow W$가 있을 때, 벡터 공간 동형 사상의 명제2에 $\Phi(\beta)$은 $W/F$의 기저가 된다.

따라서 $\dim(V)=\dim(W)$. $\quad {_\blacksquare}$

[$\Leftarrow$]  
$\beta, \gamma$를 $V,WF$의 기저라고 할 때, 함수 $\varphi$를 다음과 같이 정의하자.
$$\varphi:V \rightarrow W \quad s.t \quad \beta_i \mapsto \gamma_i$$  

이 때, $\varphi$가 벡터 공간 동형 사상임을 보이자.

[$\varphi \in L(V,W)$]  
$v_1 = a^i\beta_i, v_2 = b^i\beta_i \in V, c \in F$에 대해,

$$ \begin{aligned} \varphi(cv_1+v_2) &= (ca^i + b^i)\gamma_i \\ &= ca^i\gamma_i + b^i\gamma_i \\ &= c\varphi(v_1) + \varphi(v_2) \quad {_\blacksquare} \end{aligned} $$

[$\varphi$ is bijective]  
$\ker(\varphi) = \{ 0_V \}$이고 $\dim(V) = \dim(W)$임으로 dimension theorem에 의해 $\varphi$는 bijective이다.$\quad {_\blacksquare}$

### Remark
차원을 통해 Vector space를 분류할 수 있다. 즉, 차원이 같으면 벡터 공간 동형이고 차원이 다르면 벡터 공간 동형이 아닌 경우로 분류가 된다.

벡터 공간 동형은 집합론적 관점에서 동치 관계를 만족한다. 따라서 분할을 갖게 되며 차원이 같은 경우에는 동일한 그룹으로 볼 수 있다는것을 의미한다.

이 때, $F^n = F\times \cdots \times F$은 $\dim(F^n)=n$임으로 임의의 $n$ 차원 벡터 공간 $V$와 $V \cong F^n$이다. 이를통해 매우 추상적인 벡터 공간 $V$와 실질적인 $F^n$을 동일한 그룹으로 볼 수 있다. 그리고 이 관계를 통해 추상적인 $V$를 편하게 서술할 수 있는 관점을 제공 받는다.

## 행렬과 군
행렬 $A \in F^{m \times n}$, $B \in F^{n \times r}$이 있을 때, 행렬 방정식 $AX=B$를 풀어보자.

만약에 어떤 행렬 집합 $G$에 군 구조가 있고 $A \in G$면 군 구조의 역원 개념을 이용해 $X = A^{-1}B$이다.

군 구조를 갖는 $G$를 찾기 위해 다음의 대수적 구조를 생각해보자.

$$ G := ( \{ M \in F^{m \times n} \} , \times ) $$

$A,B \in G$에 대해, $B = A^{-1}$이려면 $AB = BA$여야 함으로 $m=n$이어야 한다.

따라서 $G$를 다음과 같이 축소시켜 보자.

$$ G := ( \{ M \in F^{n \times n} \} , \times ) $$

이제, $\delta_{ij} = \sum_{k=1}^n a_{ik}b_{kj}$를 만족해야 한다.

$b_{kj} := M_{jk} = M_{kj}^T$로 가정하면 `라플라스 전개(Laplace expansion)`에 의해 다음이 성립한다. 
$$\sum_{k=1}^n a_{ik}b_{kj} = \sum_{k=1}^n a_{ik}M_{jk} = \begin{cases} \det(A) & i=j \\ 0 & i \neq j \end{cases}$$

따라서 $b_{kj} = \frac{1}{\det(A)} M_{kj}^T$이면 $\sum_{k=1}^n a_{ik}b_{kj} = \delta_{ij}$이다.

이 때, `고전적 수반 행렬(adjugate matrix)` $\text{adj}(A) \in F^{n \times n}$은 $\text{adj}(A)_{ij} = M_{ij}^T$로 정의된다.

고전적 수반 행렬을 이용하면 역행렬은 다음과 같이 표현된다.

$$ A^{-1} = \frac{1}{\det(A)} \text{adj}(A) $$

따라서 $A^{-1}$가 정의되기 위해서는 $\det(A) \neq 0$이어야 한다. 

결론적으로 군 구조가 되기 위해서는 다음과 같아야 한다.

$$ G := ( \{ M \in F^{n \times n} | \det(M) \neq 0 \} , \times ) $$

### 참고1

$$ A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}, \quad \det(A) = ad - bc $$

$\det(A)$는 $A$의 행 벡터들에 의해 생성되는 부호있는 부피이다.

따라서 $\det(A) = 0$이라는 말은 행 벡터들이 선형 독립이 아니라서 의미있는 부피(차원)을 만들어내지 못한다는 말이다.

#### 명제1
$\det(A) = \det(A^T)$

이로써 $\det(A)$가 열 벡터들에 의해 생성되는 부호있는 부피이기도 하다는것을 알 수 있다.

**proof**

#### 명제2
$\det(AB) = \det(A)\det(B)$

**proof**

### 라플라스 전개

$\det(A) = \sum _{k=1}^n a_{kj}M_{kj}$

### 명제1
$A \in F^{n \times n}$이 있을 때, 다음이 전부 동치임을 증명하여라.

1. $A$는 역행렬이 존재한다.
2. $AX = 0$의 해는 오직 자명해인 $X=0$만 가능하다.
3. $A$는 행동치(row equivalent)하다.
4. $AX=B$는 언제나 해를 갖는다.
5. $\det(A) \neq 0$
6. $\text{rank}(A)=n$이다.
7. $A$의 모든 행 벡터는 선형 독립이다.
8. $A$의 모든 열 벡터는 선형 독립이다.

## 기본행연산
다음의 연산들을 `기본행연산(elementary row operation)`이라 한다.

1. 행에 0이 아닌 상수를 곱한다.
2. 두 행을 바꾼다.
3. 한 행에 상수를 곱한뒤 다른 행에 더해준다.

기본행연산의 목표는 $A|I$형태에서 기본행연산만을 수행해서 $I|A^{-1}$을 만들어 $A^{-1}$을 찾아내는 것이다.



## 닮음
$A,B \in \mathbb F^{n \times n}$라 하자. $A = P^{-1}BP$을 만족하는 가역행렬 $P \in \mathbb F^{n \times n}$가 존재하는 경우 $A$가 $B$와 `닮았다(similar)`라고 하고 $A \sim B$라고 표기한다.

### 명제1
$A,B \in \mathbb F^{n \times n}$가 있을 때, 다음을 증명하여라.
$$ A \sim B \Leftrightarrow \exist \beta \text{ which is basis of } \mathbb F^n \quad s.t. \quad [L_B]_\beta = A $$
$$ \text{Where, } L_B : \mathbb F^n \rightarrow \mathbb F^n \quad s.t. \quad x \mapsto Bx $$

**Proof**

[$\Rightarrow$]  
$$ \begin{aligned} & A \sim B \\ \Rightarrow \enspace & A = P^{-1}BP = [Id]^\beta_{\epsilon_n}[L_B]_{\epsilon_n}[Id]_\beta^{\epsilon_n} = [L_B]_\beta \\ & \text{Where, } \beta_i \text{ is i-th column vector of P} \quad {_\blacksquare}  \end{aligned} $$

[$\Leftarrow$]  
$$ \begin{aligned} & A = [L_B]_\beta \\ \Rightarrow \enspace & A = [Id]^\beta_{\epsilon_n}[L_B]_{\epsilon_n}[Id]_\beta^{\epsilon_n} = P^{-1}BP \\ \Rightarrow \enspace & A \sim B \quad {_\blacksquare}  \end{aligned} $$

## 고유벡터
벡터공간 $V/ \mathbb F$와 $T \in L(V)$가 있을 때, $T$의 `고유벡터(eigen vector)`는 다음을 만족하는 벡터이다.
$$ v \in V - \{0\} \quad \land \quad T(v)  = \lambda v \quad \lambda \in \mathbb F$$

이 때, 스칼라 값 $\lambda$를 `고유값(eigen value)`라 한다.

### 참고1
벡터공간 $V/ \mathbb F$와 $T \in L(V,V)$가 있고, $T$의 고유벡터와 고유값 $v, \lambda$가 있을 때, $T$의 정의역을 $S := \{ cv | c \in \mathbb F\} < V$로 `restriction`시킨 restriction map을 생각해보자.
$$ T|_S : S \rightarrow S \quad s.t. \quad cv \mapsto \lambda cv$$

이 경우에 $T|_S$는 상수 곱처럼 동작한다.

### 참고2
벡터공간 $V/ \mathbb F$와 $T \in L(V,V)$가 있고, $T$의 고유벡터와 고유값 $v, \lambda$가 있을 때, $(T - \lambda id)(v) = 0, \thinspace v \neq 0$이다. 따라서 $T - \lambda id$를 새로운 선형변환으로 보면 $v \in \ker (T - \lambda id)$이다. 

## 고유공간
벡터공간 $V/ \mathbb F$와 $T \in L(V)$가 있고, $\lambda$가 고유값이라고 하자.

이 때, 다음과 같이 정의된 집합을 $T$의 $\lambda$에 따른 `고유공간(eigen space)`이라고 한다.
$$ E_\lambda := \{ v \in V | T(v) = \lambda v \} $$

### 명제1
벡터공간 $V/ \mathbb F$와 $T \in L(V)$가 있고, $\lambda$가 고유값이라고 할 때, $E_\lambda < V$임을 증명하여라.

**Proof**

[기본 연산 법칙]  
벡터 공간 $V$의 원소들로 이루어져 있음으로, 기본적인 연산 법칙이 성립한다.

[연산에 닫혀있음]  
$a \in \mathbb F, \enspace v_1,v_2 \in E_\lambda$라 하자. $T(av_1 + v_2) = \lambda(av_1 + v_2)$임으로 $av_1 + v_2 \in E_\lambda$이다. $\quad {_\blacksquare}$

[$+$ 항등원의 존재성]  
$T(0_V) = 0_V$이고 $a \in \mathbb F \Rightarrow a0_V = 0_V$임으로 $0_V \in E_\lambda$이다. $\quad {_\blacksquare}$

[$+$ 역원의 존재성]  
상수곱이 정의되어 있음으로, 환의 명제2에의해 존재한다. $\quad {_\blacksquare}$

### 명제2
벡터공간 $V/ \mathbb F$와 $T \in L(V)$가 있고, $\lambda$가 고유값이라고 할 때, $E_\lambda = \ker(T - \lambda id)$임을 증명하여라.

**Proof**

$T(v) = \lambda v$ 조건은 $(T - \lambda id)(v) = 0$ 조건과 동치이다. 즉, $E_\lambda$는 선형변환 $(T - \lambda id)$의 null space가 된다. $\quad {_\blacksquare}$

## 대각화(선형변환)
벡터공간 $V/ \mathbb F$와 $T \in L(V)$가 있을 때, $[T]_\beta$가 대각행렬이 되게 만드는 $V$의 기저 $\beta$가 존재하는 경우 $T$를 `대각화 가능(diagonalizable)`하다고 한다. 

### 명제1
벡터공간 $V/ \mathbb F$와 $T \in L(V)$가 있을 때, $T$의 고유벡터로 이루어진 기저가 존재할 경우 대각화 가능함을 증명하여라.

**Proof**

$\dim(V) = n$일 때, 고유벡터를 $v_1, \cdots, v_n$이라 하고 해당하는 고유값들을 $\lambda_1, \cdots , \lambda_n$이라 하자. 

고유벡터로 이루어진 기저를 $\beta$라하고 $\beta_i = v_i$라 하자.

이 때, $T(v_i) = \lambda_i v_i$임으로 $[T]_\beta$는 대각행렬이다. $\quad {_\blacksquare}$

### 명제2
벡터공간 $V/ \mathbb F$와 $T \in L(V)$가 있을 때, $\dim(V) = n$이고 $T$의 고유값들이 $n$개이면서 서로 다를 경우 대각화 가능함을 증명하여라.

**Proof**

고유벡터를 $v_1, \cdots, v_n$이라 하고 해당하는 고유값들을 $\lambda_1, \cdots , \lambda_n$이라 하자. 

고유벡터의 집합이 선형종속이라고 가정하고, 일반성을 잃지 않고 선형 종속인 원소를 $v_n$이라고 하자.

$v_n$은 선형종속임으로 다음이 성립한다.
$$  \begin{aligned} & v_n = a_1v_1 + \cdots + a_{n-1}v_{n-1} \\ \Rightarrow \enspace & T(v_n) = T(a_1v_1+ \cdots + a_{n-1}v_{n-1}) \\ \Rightarrow \enspace & \lambda_n v_n = \lambda_1a_1v_1 + \cdots + \lambda_{n-1}a_{n-1}v_{n-1} \end{aligned} $$

동시에 다음도 성립한다.
$$ \begin{aligned} & v_n = a_1v_1 + \cdots + a_{n-1}v_{n-1} \\ \Rightarrow \enspace &  \lambda_nv_n = \lambda_na_1v_1 + \cdots + \lambda_na_{n-1}v_{n-1} \end{aligned} $$

두 식을 빼면 다음과 같다.
$$ 0_V = a_1(\lambda_n - \lambda_1)v_1 + \cdots + a_{n-1}(\lambda_n - \lambda_{n-1})v_{n-1} $$

이 때, 서로 다른 고유값을 가짐으로 $a_1 = \cdots = a_{n-1} = 0$이되고 $v_n = 0_V$가 된다. 이 때, 고유값은 $0_V$가 아님으로 모순이 발생한다.

고유벡터의 집합이 선형종속이라 가정하였을 때 모순이 발생함으로, 고유벡터의 집합은 선형독립이 되고 고유벡터의 수가 $V$의 차원과 동일함으로 고유벡터의 집합은 기저가된다. 고유벡터로 이루어진 기저가 존재함으로 명제1에 의해 대각화 가능하다. $\quad {_\blacksquare}$ 

#### 참고1
반드시 서로 다른 고유값들을 가져야만 대각화 가능한 것은 아니다.

예를 들어 다음의 행렬을 생각해보자.
$$ A= \begin{bmatrix} 4 & 0 & 1 \\ 2 & 3 & 2 \\ 1 & 0 & 4 \end{bmatrix} $$

다음 행렬의 특성다항식의 근은 $\lambda = 3,5$로 두개의 근을 갖지만 $L_A : \R^2 \rightarrow \R^2$는 대각화 가능하다.

### 명제3
$n$차원 벡터공간 $V/ \mathbb F$와 $T \in L(V)$가 있을 때, $T$가 대각화 가능하다는 말과 고유값 $\lambda_1, \cdots \lambda_k, \enspace k \le n$에 대해 $V = \oplus_i^k E_{\lambda_i}$가 동치임을 증명하여라.

**Proof**

[$\Rightarrow$]  
$\exist \beta = \{ v_{1,1}, \cdots, v_{1,m_1} \cdots, v_{k,1}, \cdots, v_{k,m_k}\}$


### 참고1
$A \in \mathbb F^{n \times n}$과 $L_A : \mathbb F^n \rightarrow \mathbb F^n \quad s.t. \quad x \mapsto Ax$가 있고 $L_A$가 대각화 가능하다고 하자.

$L_A$의 고유벡터로 이루어진 기저 $\beta$라 하면 다음이 성립한다.
$$ [L_A]_\beta = [Id]^\beta_{\epsilon_n}[L_A]_{\epsilon_n}[Id]_\beta^{\epsilon_n} = P^{-1}AP $$

즉, $[L_A]_\beta \sim A$이다.

## 대각화(행렬)
$A \in \mathbb F^{n \times n}$와 대각행렬 $D \in \mathbb F^{n \times n}$가 있을 때, $D \sim A$면 $A$가 대각화 가능하다고 한다. 그리고 이는 선형변환 $L_A$가 대각화가능하다는 말과 동치이다.

### 참고1
대각화 가능은 어떤 `체(field)`를 사용하느냐에 의존한다. 다음 예시를 보자.

회전 변환으로 잘 알려진 선형변환 $L_R$이 다음과 같이 주어졌다.
$$ L_R : \mathbb F^n \rightarrow \mathbb F^n \quad s.t. \quad x \mapsto Rx$$
$$ \text {where, } R = \begin{bmatrix} \cos \theta & - \sin \theta \\ \sin \theta & \cos \theta \end{bmatrix}, \quad 0 < \theta < 2\pi \land \theta \neq \pi $$

이 때, $L_R$이 대각화 가능한지 알아보자. $L_R$이 대각화 가능한지 알아보기 위해서는 고유벡터를 찾아야한다. 즉, 다음을 만족 $v \in \mathbb F^n - \{0\}$를 찾아야 한다.
$$ \begin{equation} \begin{aligned} & L_R(v) = \lambda v, \quad \lambda \in \mathbb F \\ \Leftrightarrow \enspace & Rv = \lambda v \\ \Leftrightarrow \enspace & (R -\lambda I)v = 0  \end{aligned} \end{equation} $$

$v \neq 0$이라는 사실을 통해 $R-\lambda I$가 역행렬이 없어야 함을 알 수 있다. 따라서 $\det(R - \lambda I) = 0$이어야 하고 $\det(R - \lambda I)$를 행렬의 `특성다항식(characteristic polynomial)`이라고 한다.

특성다항식이 0이되는 경우를 찾아보자.
$$ \begin{equation} \begin{aligned} & (\cos \theta - \lambda)^2 + \sin \theta^2 = 0 \\ \Leftrightarrow \enspace & \lambda^2 - 2 \cos \theta \lambda + 1 = 0 \end{aligned} \end{equation}   $$

이제, $\mathbb F = \R$인 경우를 생각해보자. 식(2)의 판별식을 확인해보면 모든 $\theta$에 대해서 0보다 작음을 알 수 있으며 따라서 $\lambda \in \R$에서는 위의 특성다항식을 만족하는 해가 존재하지 않는다. 따라서 고유벡터 또한 존재하지 않고 대각화 불가능하다.

다음으로 $\mathbb F = \mathbb C$인 경우를 생각해보자. $\lambda \in \mathbb C$에서는 위의 특성다항식을 만족하는 해 $\lambda = \cos \theta \pm i \sin \theta = e^{\pm i \theta}$가 존재한다. 고유값에 해당하는 고유벡터를 찾기 위해서 식(1)에 대입한다.

먼저, $\lambda = \cos \theta + i \sin \theta$ 경우를 대입해 정리하면 다음과 같다.
$$ \begin{aligned} & -i\sin \theta v_1 - \sin \theta v_2 = 0 \\ \Leftrightarrow \enspace & -i v_1 = v_2  \\ \Leftrightarrow \enspace & v_1 = t, \quad v_2 = -i t \quad t \neq 0 \end{aligned}  $$

동일하게 $\lambda = \cos \theta - i \sin \theta$ 경우를 대입해 정리하면 다음과 같다.
$$ v_1 = s, \quad v_2 = i s \quad s \neq 0 $$

$t,s$를 각각 $1$로 잡아주면 다음과 같은 두개의 고유벡터로 이루어진 기저를 얻을 수 있다.
$$ \beta = \left( \begin{bmatrix} 1 \\ -i \end{bmatrix}, \begin{bmatrix} 1 \\ i \end{bmatrix} \right) $$ 

따라서, $L_R$은 대각화 가능하며 대각행렬은 다음과 같다.
$$ [L_R]_\beta = \begin{bmatrix} e^{i\theta} & 0 \\ 0 & e^{-i\theta} \end{bmatrix} $$

## 특성다항식(행렬)
$A \in \mathbb F^{n \times n}$가 있을 때, $\det(A - tI)$를 $A$의 특성다항식이라하고 $\varphi_A(t)$로 표기한다.

### 명제1
$A \in \mathbb F^{n \times n}$가 있을 때 다음을 증명하여라
$$\varphi_A(t) = (-1)^n(t^n + a_1t^{n-1} + \cdots + a_{n-1}t + a_n) \quad a_n =\begin{cases} -\mathrm{tr} (A) & i = 1  \\ (-1)^i\det(A) & i = 2 \cdots n \end{cases}$$

**Proof**

수학적 귀납법

어떤 선형변환이 주어졌을 때, 이를 간단하게 나타내는 방법

## 선형변환의 다양한 정의
벡터공간 $V/ \mathbb F$와 임의의 기저 $\beta$ 그리고 $T \in L(V,V)$가 있을 때, 행렬의 여러 개념들을 선형변환에서는 다음과 같이 정의한다.
$$ \det(T) := \det([T]_\beta) $$
$$ \mathrm{tr}(T) := \mathrm{tr}([T]_\beta) $$

### 보조정리1
$A,B \in \mathbb F^{n \times n}$가 $A \sim B$일 때, $\det(A) = \det(B)$임을 증명하여라.

**Proof**

$$ \det(A) = \det(P^{-1}BP) = \det(P^{-1})\det(B)\det(P) = \det({P^{-1}P})\det(B) = \det(B) \quad {_\blacksquare} $$

### 보조정리2
$A,B \in \mathbb F^{n \times n}$가 $A \sim B$일 때, $\mathrm{tr}(A) = \mathrm{tr}(B)$임을 증명하여라. 

**Proof**

$$ \mathrm{tr}(A) = \mathrm{tr}(P^{-1}BP) = \mathrm{tr}(PP^{-1}B) = \mathrm{tr}(B) \quad (\because \mathrm{tr}(AB) = \mathrm{tr}(BA)) \quad {_\blacksquare}  $$

### 명제1
벡터공간 $V/ \mathbb F$와 $T \in L(V,V)$가 있을 때, 선형변환의 determinant와 trace가 well-defined 됨을 증명하여라.

**Proof**

well-defined 되기 위해서는 기저의 선택에 관계없이 일정함을 보이면 된다. $V$의 두 기저를 $\beta,\gamma$라 하자. 그러면 $[T]_\beta \sim [T]_\gamma$임으로 보조정리1,2 에 의해 증명이 끝난다. $\quad {_\blacksquare}$

### 명제2
벡터공간 $V/ \mathbb F$와 $T \in L(V,V)$가 있을 때, 다음을 증명하여라.
$$ \lambda \in \mathbb{F} \text{ is eigen value of } T \Leftrightarrow \det(T - \lambda id) = 0 $$

**Proof**

[$\Rightarrow$]  
$\beta$를 $V$의 기저라고 하자.
$$ \begin{aligned} & \exist v \in V - \{ 0_V \} \quad s.t. \quad (T - \lambda id)(v) = 0_V \\ \Rightarrow \enspace & [T - \lambda id]_\beta [v]_\beta = 0_F \\ \Rightarrow \enspace & \det( [T - \lambda id]_\beta ) = 0 \quad (\because [v]_\beta \neq 0_F) \quad {_\blacksquare}  \end{aligned} $$
$$ \text{Where, } \beta \text{ is a any basis of } V $$

[$\Leftarrow$]  
$$ \begin{aligned} & \det(T-\lambda id) = 0 \\ \Rightarrow \enspace &  \det([T - \lambda id]_\beta) = 0 \\ \Rightarrow \enspace & \exist v \in V - \{ 0_V \} \quad s.t. \quad [T - \lambda id]_\beta [v]_\beta = 0_F \\ \Rightarrow \enspace & [T]_\beta [v]_\beta = \lambda [v]_\beta \\ \Rightarrow \enspace & T(v) = \lambda v \quad {_\blacksquare}  \end{aligned}  $$

> $\det(A)=0 \Rightarrow \exist x \neq 0 \quad s.t. \quad Ax = 0$를 증명하여라.

## 특성다항식(선형변환)
벡터공간 $V/\mathbb F$와 $T \in L(V,V)$가 있을 때, $T$의 특성다항식은 다음과 같이 정의된다.
$$ \varphi_T(t) = \det(T - tid) $$

특성다항식의 근이 고유값이 된다.

---

$\lambda_1, \cdots, \lambda_k$

$$\exist v \in V - \{0\} \quad s.t. \quad (T - \lambda id)(v) = 0 \Rightarrow [T - \lambda id]_\beta [v]_\beta = 0$$

# 대칭행렬
symmetric matrix일 때, eigenvector는 서로 수직한다.

> 참고  
> [book] (Lai et al) Introduction to Continuum Mechanics Chapter 2.23

# Definite Matrix
$\mathbf M \in Mat_{nn}(\R)$라 할 때, 다음을 만족하는 행렬을 `positive-definite`라고 한다.
$$ \mathbf x \in \R^n - \{ 0 \} \Rightarrow \mathbf x^T \mathbf M \mathbf x > 0 $$

### 명제1
$\mathbf M \in Mat_{nn}(\R)$라 할 때, 다음을 증명하여라.
$$ \mathbf M \text{ is positive definite} \Leftrightarrow \text{all eigenvalues are positive} $$

> 참고  
> [Definite Matrix - Wiki](https://en.wikipedia.org/wiki/Definite_matrix)
